{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from kubernetes import client, config\n",
    "\n",
    "# Load Kubernetes config\n",
    "config.load_kube_config()\n",
    "\n",
    "# Create Kubernetes API instances\n",
    "v1 = client.CoreV1Api()\n",
    "batch_v1 = client.BatchV1Api()\n",
    "\n",
    "# Function to create a Kubernetes job manifest\n",
    "def create_job_manifest(name, cpu, memory, command):\n",
    "    return {\n",
    "        \"apiVersion\": \"batch/v1\",\n",
    "        \"kind\": \"Job\",\n",
    "        \"metadata\": {\"name\": name},\n",
    "        \"spec\": {\n",
    "            \"template\": {\n",
    "                \"spec\": {\n",
    "                    \"containers\": [\n",
    "                        {\n",
    "                            \"name\": name,\n",
    "                            \"image\": \"busybox\",  # Replace with your desired image\n",
    "                            \"command\": [\"sh\", \"-c\", command],\n",
    "                            \"resources\": {\"requests\": {\"cpu\": cpu, \"memory\": memory}},\n",
    "                        }\n",
    "                    ],\n",
    "                    \"restartPolicy\": \"Never\",\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "# Read and process the trace file\n",
    "trace_file = \"filtered_cluster_job_log.json\"\n",
    "with open(trace_file, \"r\") as f:\n",
    "    trace_data = json.load(f)\n",
    "\n",
    "# Iterate over each job in the trace\n",
    "for job in trace_data:\n",
    "    job_id = job[\"jobid\"]\n",
    "    user = job[\"user\"]\n",
    "    attempts = job.get(\"attempts\", [])\n",
    "\n",
    "    # Ensure at least one valid attempt exists\n",
    "    if not attempts:\n",
    "        print(f\"Skipping job {job_id}: No valid scheduling attempts found.\")\n",
    "        continue\n",
    "\n",
    "    # Process the first attempt (or customize for your use case)\n",
    "    attempt = attempts[0]\n",
    "    start_time = attempt.get(\"start_time\")\n",
    "    end_time = attempt.get(\"end_time\")\n",
    "    resources = attempt.get(\"detail\", [])\n",
    "\n",
    "    # Extract resource details (example uses CPU and memory placeholders)\n",
    "    # You can refine based on your needs (e.g., GPU info)\n",
    "    if resources:\n",
    "        server_info = resources[0]\n",
    "        ip = server_info[\"ip\"]\n",
    "        gpus = server_info.get(\"gpus\", [])\n",
    "        cpu_request = \"1\"  # Placeholder for CPU (customize as needed)\n",
    "        memory_request = \"1Gi\"  # Placeholder for memory (customize as needed)\n",
    "    else:\n",
    "        print(f\"Skipping job {job_id}: No resource details found.\")\n",
    "        continue\n",
    "\n",
    "    # Log the job details\n",
    "    print(f\"Scheduling job {job_id} from user {user} on server {ip} using GPUs: {gpus}\")\n",
    "\n",
    "    # Create and deploy the Kubernetes job\n",
    "    command = f\"echo 'Processing job {job_id}'\"\n",
    "    job_manifest = create_job_manifest(job_id, cpu_request, memory_request, command)\n",
    "    batch_v1.create_namespaced_job(namespace=\"default\", body=job_manifest)\n",
    "\n",
    "    # Simulate submission delay based on the job's submission time\n",
    "    if start_time:\n",
    "        print(f\"Job {job_id} scheduled with start time: {start_time}\")\n",
    "        time.sleep(2)  # Adjust delay as per your simulation needs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from kubernetes import client, config\n",
    "\n",
    "# Load Kubernetes config\n",
    "config.load_kube_config()\n",
    "\n",
    "# Create API instances\n",
    "v1 = client.CoreV1Api()\n",
    "batch_v1 = client.BatchV1Api()\n",
    "\n",
    "# Load trace from the JSON file\n",
    "with open(\"filtered_cluster_job_log.json\", \"r\") as f:\n",
    "    trace = json.load(f)\n",
    "\n",
    "# Helper function to parse attempts and find the first valid one\n",
    "def get_first_valid_attempt(attempts):\n",
    "    for attempt in attempts:\n",
    "        if attempt.get(\"start_time\") and attempt.get(\"end_time\"):\n",
    "            return attempt\n",
    "    return None\n",
    "\n",
    "# Function to create a job manifest from trace details\n",
    "def create_job_manifest(name, cpu, memory, command):\n",
    "    return {\n",
    "        \"apiVersion\": \"batch/v1\",\n",
    "        \"kind\": \"Job\",\n",
    "        \"metadata\": {\"name\": name},\n",
    "        \"spec\": {\n",
    "            \"template\": {\n",
    "                \"spec\": {\n",
    "                    \"containers\": [\n",
    "                        {\n",
    "                            \"name\": name,\n",
    "                            \"image\": \"busybox\",  # Replace with your desired image\n",
    "                            \"command\": [\"sh\", \"-c\", command],\n",
    "                            \"resources\": {\"requests\": {\"cpu\": cpu, \"memory\": memory}},\n",
    "                        }\n",
    "                    ],\n",
    "                    \"restartPolicy\": \"Never\",\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "# Process each job in the trace and deploy workloads\n",
    "for job in trace:\n",
    "    if job[\"status\"] != \"Pass\":\n",
    "        continue  # Skip jobs that didn't pass\n",
    "    \n",
    "    job_name = job[\"jobid\"].replace(\"application_\", \"\").replace(\"_\", \"-\")\n",
    "    submitted_time = job.get(\"submitted_time\")\n",
    "    attempts = job.get(\"attempts\", [])\n",
    "    \n",
    "    # Find the first valid attempt\n",
    "    first_attempt = get_first_valid_attempt(attempts)\n",
    "    if not first_attempt:\n",
    "        print(f\"Skipping job {job_name} due to missing valid attempts.\")\n",
    "        continue\n",
    "\n",
    "    # Extract scheduling information\n",
    "    start_time = first_attempt.get(\"start_time\")\n",
    "    gpus = first_attempt[\"detail\"][0].get(\"gpus\", []) if first_attempt[\"detail\"] else []\n",
    "\n",
    "    # Simulate workload deployment with some assumptions for resources\n",
    "    cpu_request = f\"{len(gpus) * 500}m\"  # Assume 500m CPU per GPU\n",
    "    memory_request = f\"{len(gpus) * 512}Mi\"  # Assume 512Mi memory per GPU\n",
    "    command = f\"echo 'Job {job_name} running with {len(gpus)} GPUs'\"\n",
    "\n",
    "    # Simulate the delay based on submitted time and start time\n",
    "    delay = 5  # Default delay in seconds\n",
    "    print(f\"Waiting {delay} seconds before deploying job {job_name}...\")\n",
    "    time.sleep(delay)\n",
    "\n",
    "    # Create and deploy the job\n",
    "    job_manifest = create_job_manifest(job_name, cpu_request, memory_request, command)\n",
    "    batch_v1.create_namespaced_job(namespace=\"default\", body=job_manifest)\n",
    "    print(f\"Deployed job {job_name} with {len(gpus)} GPUs.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
